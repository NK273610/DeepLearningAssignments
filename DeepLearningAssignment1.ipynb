{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sKGsmsab5I1S"
   },
   "source": [
    "# <center>Assignment 1</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "q5VD__J65I1U"
   },
   "source": [
    "There are 2 main parts asked in this assignment - Tensorflow Basics and Neural Networks. You can choose to code in Python2 or Python3. All the imports made in this notebook are as below; if these imports work, you are (mostly) set to complete the assignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "B4teB1gh5I1V"
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function,division\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import random \n",
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vWzfE86tusct"
   },
   "source": [
    "## Tensorflow - Basics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gtgV4CJM5I1Z"
   },
   "source": [
    "### I. Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "waXA1j7A5I1a"
   },
   "source": [
    "<b>1a. Creating Sample Data </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "LrDL6noo5I1b"
   },
   "outputs": [],
   "source": [
    "x = np.random.randn(100,3) # 100 data points of dimension 3\n",
    "w = np.array([[1],[2],[3]])\n",
    "b = 10\n",
    "y = np.array((x * w.transpose()).sum(axis=1)+b).reshape(100,1) # Write code to create the target. Use Numpy operations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "J6m9Ibn65QcP"
   },
   "source": [
    "**1b. Plot Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 270
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 565,
     "status": "ok",
     "timestamp": 1526583256432,
     "user": {
      "displayName": "Nikhil Dhirmalani",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "117732879546167846741"
     },
     "user_tz": 180
    },
    "id": "lS4Hlv8k5UeZ",
    "outputId": "2f4ae745-f7e8-4dd2-e1eb-2639b4d3c3ba"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD9CAYAAAC1DKAUAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nWQAkqaYsAJJUUxYASaqp/w/aJzVWoidd2AAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f693b08c950>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Explore the data by plotting whatever makes you understand the problem better. \n",
    "# Your code here.\n",
    "for i in range(3):\n",
    "  plt.hist(x[:,i], normed=True, bins=30)\n",
    "  plt.ylabel('Probability');\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qo8hagle5I1c"
   },
   "source": [
    "<b>2. Creating Placeholders</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "9aM6fyvd5I1e"
   },
   "outputs": [],
   "source": [
    "X = tf.placeholder(dtype=tf.float32,shape=[None,3]) \n",
    "Y_Expected = tf.placeholder(dtype=tf.float32,shape=[100,1]) # Write code to create the placeholder for target."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IIcGDu2s5I1f"
   },
   "source": [
    "<b>3. Creating Variables</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "OJd_anpk5I1h"
   },
   "outputs": [],
   "source": [
    "b = tf.Variable(dtype=tf.float32,initial_value=np.zeros(shape=(1,1)),name=\"b\")\n",
    "W = tf.Variable(dtype=tf.float32,initial_value=np.zeros(shape=[3,1]),name=\"w\") # Write code to instantiate W with zeros. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cZItc9VZ5I1k"
   },
   "source": [
    "<b> 4. Creating Compute Graph </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "HwpRYAc85I1k"
   },
   "outputs": [],
   "source": [
    "Y = tf.add(tf.matmul(X, W), b) # Define the equation to compute the output variable.\n",
    "cost = tf.reduce_sum(tf.pow(Y_Expected-Y, 2))/(2*100) # Define the cost function.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XoqEq-Mj5I1m"
   },
   "source": [
    "<b> 5. Training and optimizer </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 527
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 431,
     "status": "ok",
     "timestamp": 1526583267295,
     "user": {
      "displayName": "Nikhil Dhirmalani",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "117732879546167846741"
     },
     "user_tz": 180
    },
    "id": "TkF3TNpt5I1o",
    "outputId": "674ffb69-901e-45c5-ae91-710ba571a59a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 56.14354\n",
      "1 45.44863\n",
      "2 36.837368\n",
      "3 29.891996\n",
      "4 24.281485\n",
      "5 19.742783\n",
      "6 16.066317\n",
      "7 13.0847225\n",
      "8 10.664023\n",
      "9 8.6967535\n",
      "10 7.0965357\n",
      "11 5.793817\n",
      "12 4.732503\n",
      "13 3.8672736\n",
      "14 3.1614718\n",
      "15 2.5854023\n",
      "16 2.1149824\n",
      "17 1.7306633\n",
      "18 1.4165558\n",
      "19 1.1597369\n",
      "20 0.9496863\n",
      "21 0.77783513\n",
      "22 0.6371973\n",
      "23 0.5220743\n",
      "24 0.42781603\n",
      "25 0.35062438\n",
      "26 0.28739655\n",
      "27 0.2355982\n",
      "28 0.19315626\n",
      "29 0.15837568\n"
     ]
    }
   ],
   "source": [
    "# This part has been done for you already! Just run it after you finish coding the above sections. \n",
    "sess = tf.InteractiveSession()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.1)\n",
    "train_op = optimizer.minimize(cost)\n",
    "for epoch in range(30):\n",
    "    epoch_cost,_ = sess.run([cost,train_op],feed_dict={X:x,Y_Expected:y})\n",
    "    print (epoch,epoch_cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nnMq3Dxx5I1q"
   },
   "source": [
    "<b> 5. Print out parameters </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 289,
     "status": "ok",
     "timestamp": 1526583271167,
     "user": {
      "displayName": "Nikhil Dhirmalani",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "117732879546167846741"
     },
     "user_tz": 180
    },
    "id": "Htz0trvg5I1s",
    "outputId": "4f842988-493e-4af0-f62f-11eb9e4a15a4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W: [[0.8468066]\n",
      " [1.96483  ]\n",
      " [2.8201952]]\n",
      "b: [[9.532655]]\n"
     ]
    }
   ],
   "source": [
    "# Replace the None with the correct operation. You should get W close to [[1],[2],[3]] and b close to 10. \n",
    "print(\"W:\",sess.run(W))\n",
    "print(\"b:\",sess.run(b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1xXx4-CO5I1v"
   },
   "source": [
    "### II. Matrix Multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "0ZylKoT7v9J2"
   },
   "outputs": [],
   "source": [
    "def ndmatmul():\n",
    "    \"\"\"\n",
    "      # 3d x 2d Matmul operation. \n",
    "      You may find some of these functions useful: einsum, tile, expand_dims.\n",
    "      :return a: Placeholder for 3d tensor [float64]\n",
    "              b: Placeholder for 2d tensor [float64]\n",
    "              c: Matrix Product\n",
    "      \"\"\"\n",
    "    a = tf.placeholder(dtype=tf.float64,shape=[5,2,3])\n",
    "    b = tf.placeholder(dtype=tf.float64,shape=[3,1])\n",
    "    c = tf.einsum('abc,cd->abd',a,b)\n",
    "    return a,b,c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "oHHeXiBOxyI2"
   },
   "outputs": [],
   "source": [
    "A,B,C = ndmatmul()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 306
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 329,
     "status": "ok",
     "timestamp": 1526583279558,
     "user": {
      "displayName": "Nikhil Dhirmalani",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "117732879546167846741"
     },
     "user_tz": 180
    },
    "id": "Rldu3MIfx3Yi",
    "outputId": "2b554884-aa4f-43ef-a0a7-a036bbc447cf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 2, 3)\n",
      "(3, 1)\n",
      "(5, 2, 1)\n",
      "[[[-0.51783421]\n",
      "  [ 1.98033132]]\n",
      "\n",
      " [[-1.12404125]\n",
      "  [ 1.00805567]]\n",
      "\n",
      " [[-0.40371716]\n",
      "  [ 1.43240346]]\n",
      "\n",
      " [[ 0.49588387]\n",
      "  [-1.49477015]]\n",
      "\n",
      " [[-0.26736846]\n",
      "  [ 0.38907473]]]\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(1)\n",
    "a = np.random.randn(5,2,3)\n",
    "b = np.random.randn(3,1)\n",
    "c = np.matmul(a,b)\n",
    "print(a.shape)\n",
    "print(b.shape)\n",
    "print(c.shape)\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 272
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 560,
     "status": "ok",
     "timestamp": 1526583282666,
     "user": {
      "displayName": "Nikhil Dhirmalani",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "117732879546167846741"
     },
     "user_tz": 180
    },
    "id": "BX2VDVzx01vp",
    "outputId": "b98482f6-b160-4fad-d3cd-609accabc61e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[-0.51783421]\n",
      "  [ 1.98033132]]\n",
      "\n",
      " [[-1.12404125]\n",
      "  [ 1.00805567]]\n",
      "\n",
      " [[-0.40371716]\n",
      "  [ 1.43240346]]\n",
      "\n",
      " [[ 0.49588387]\n",
      "  [-1.49477015]]\n",
      "\n",
      " [[-0.26736846]\n",
      "  [ 0.38907473]]]\n",
      "Correct!\n"
     ]
    }
   ],
   "source": [
    "# Will give error if function not implemented. Your output should match Numpy's output.\n",
    "sess = tf.InteractiveSession()\n",
    "c_tensor = sess.run(C,feed_dict={A:a,\n",
    "                            B:b})\n",
    "print(c_tensor)\n",
    "if (c_tensor-c<10**-10).all():\n",
    "    print(\"Correct!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "M_B3PwLX2mYc"
   },
   "source": [
    "### III. Experiments with Feed-forward NN on MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cX231VZk5I13"
   },
   "source": [
    "In this Qn, you will experiment with Feed-forward Neural nets while training on the MNIST dataset. Read more about it <a href = \"https://en.wikipedia.org/wiki/MNIST_database\">here</a>. A random sample of the images has been shown to you. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 405
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1629,
     "status": "ok",
     "timestamp": 1526602174072,
     "user": {
      "displayName": "Nikhil Dhirmalani",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "117732879546167846741"
     },
     "user_tz": 180
    },
    "id": "GX5Q-nJv5I14",
    "outputId": "3946f409-22fe-4913-e03e-eaedf96c9a0d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "(55000, 784)\n",
      "(55000, 10)\n",
      "(10000, 784)\n",
      "(10000, 10)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAADcAAAD8CAYAAADT9DwxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4yLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvNQv5yAAAER9JREFUeJztnX1sFOW+xz87uy2lUFq0XlEEROKM\nB1+qIHig9rZ6q+iFUAha/iCGmAOGFAKXGiIoEVTQA8cEQQzBe7FXriZ4eWmDB4ioVQuBaEMoYoJz\nQKVVvOXlQO3Llm27fe4f+3K23ZeZ3c7uzHrmk0w6O/PM8zy/zszz8n1+zzMOIQS/VySzM5BMbOPS\nFdu4dOV3bZwr0QsVRdkE/BEQwDJVVesNy5VBJHTnFEUpBu5UVXUK8Cdgi6G5MohEH8t/A2oAVFU9\nAwxXFGWYYbkyiESNGwFcDvl92X8sGsLATTdGFSgOg+IxlESN+5W+d+pW4P8Gnh1jSdS4w8BTAIqi\nTAB+VVW1zbBcGYQj0V6Boih/Bv4V6AUWq6p6KkbwiIl4PB5qa2upr69n3759DBkyhOPHjyOEwOFw\n0NXVhcsVVlvpfgUSNi5OIiby9ddfU1hYSHFxMdOmTaO8vJxffvmFe+65B4C8vLxIl+k2LuFK3CgK\nCwv5/PPPg79vv/124yIXQqRiC6O3t1fMmjVLZGVlicGDBwtJkoLbyZMnI10SQHe6phl35syZPgaF\nbgUFBaK7u3vAxpnWcK6uriY7O5u2tja6urrwer14vV5aW1s5ffo0NTU1A07DNONWrVrFjz/+SHZ2\nNk6nM+x8R0fHgNMwtctz0003JTV+y/XnWlpajIvMrAIlGs8995yQJEm0tLQMuEDRVc8pirIRKMJX\nL74BzAQmAn/3B/mLqqoH4v3Hut1u2trauPnmm/n+++8pKiri6tWrnDp1itzc3HijC0fLelmWH5Fl\n+aB//0ZZlptkWf5vWZZnDPTObdu2Lbh/4403BqsCDQytCuqAp/37LcAQILx4S4Bz587hdDpxOp3M\nnz+fpqYmvF6vEVEDcbYtFUV5Dt/j6cXX5ckELgFLVFW9EuNSIxuwutuWuktLRVHK8OklS4D/AVaq\nqvoo0ACsjTODKUHXnVMUZRrwGvCEqqpX/ccC6lcWIFRVnZDMjCaC5p1TFCUX+AswI8Swr4ACv/r1\nMb6euOXQvHP+92wt8LeQwy1AAdAEtAMyMFFV1dbkZDNB4ilaQ6qHd2VZLgv5fUSWZTneqiBBUt4r\nsNWvVGOq+tXQ0IAkSTidzuBfp9PJ/v37E8xWXxLSUFRVPaYoyglFUY7hV7+ihVUUZZOqqhHPffDB\nBzgcDoYNG8Zjjz1GQUEBbW1t7Nixg+nTp0fs5ymK8qV/V7s9m0iBEkfBUyzL8l9jlQ5NTU1hxyRJ\nEuXl5ZYpUKIRHDCJxqhRoyIe/+677waceLKN6z9gEpXu7m6OHTvG/fffz7Bhw6JqKIqi1CqKsktR\nlHytOE3viV+9epXa2lpKSkooKiri9OnTrF69mjvvvDNi+Hjas8kWZftXGUF+++03brjhhogXPf/8\n81rx7ge2aQVK9p0LVhn9GTx4MBUVFVRVVfHZZ59RVVWFLMsAnD59WiveEkD7pUxmaekvMf8cq7QM\nxe12i4ULF4r58+eL3t7eiGFkWf5KluUDsiz/i1baSTdORGhbejyemEZKkiQKCwujnbZMVRCG2+1m\n+vTpEc95vV727dsHwLVr1wacVsrVr7a2NjweD06n0/foAA6HAyF8Y3IAmzZtYvHiqI0e/Wjd2mSo\nX42NjSIzM1M4HI7gNn78eOFyucTrr78e85GN57HUc+fqgG/8+4aoX6NHj8bj8QwkCl3Y6hfY6pet\nfqUSW/2KUD3Eq36ZshnVK9AqwaxdWvbDVr/0UFtby7hx43C5XDidTlwuV3D/m2++0Y4gBkn3/fKr\nX/8RLZ7GxkbGjRvHfffdx5QpUwCffnL06FEefvhhDh8+zKBBg0Lj+8q/a331KxorV64URUVF4vr1\n6/1PWabLo6l+RaKmpoaNGzcO2A8s2RrKCOBErAAej4fq6mrefPNNLl++zIULF4LnqqqqwoRZRVFq\n0deeNVf9OnfuHE888QTz5s3j5MmT/PzzzwghmD9/PufPn4+oOMfTnk22cVHVL4ClS5dSV1fHk08+\nyaJFi3A4HFRWVrJjx46oYq2f/cC9Wombpn4BVFZW8vbbb1NdXc0777xDc3Mzd911F+3t7VrxlqBD\n/UqqcaqqHiPGO1daWkpFRQUZGRmAzxfM6XSyc+fOqHH6q4LpwCuaGUhRO08IIcTOnTs1q4Bff/1V\nbNiwIVYQy1QFfRgzZgwvv/xy1PMej4cdO3YMuGUSQG9ndaDqlwDfYMfgwYMB3yM4e/Zstm/fHlS9\nhPApYD09PTHzrJlhP5r1nKIojwD3qKo6RVGUG4GTQC2wSlXVv+pNCCAjI4NJkyZRX1/P5cuXeffd\nd/ucX7RoEbfddls8UcYk5erX8ePHE700bmz1C9JT/dIrp08DXsKnfv0GfB5yWs9YmSl+KnoKlID6\nVRqifu0FfgP+ANyMRuPYLPTcublAPvC/iqIEjh0DKoBTwM/A7cnI3EBJqCeuKMqrQJOqqv/l//09\nMNlq0p49rVMHtmNbqjFd2ksmCRkX6Kf5Hdu2oOHYFiuuQ4cOsWLFiqBW2X/rP3ysKMqX/i3ywHoo\nyezHxZL2Lly4IJYvXy5cLlfUeXSSJInhw4dbtj8XUdqrqalh1KhRbN68mQULFgQnSwS2jo4OHn/8\ncQAeffTRhBM3Rdprbf1HdfjMM88wcuTIPufb2to4fPgw+fn5fPjhh33OWV7ae+qpp8jMzASgqKgo\n7D0bMWIEQ4YM4eLFi32kdEgDaS87O5uSkpKoF5WXlxPNu9aPtaW93bt3c/bsWebMmcOcOXP6nHvv\nvfe45ZZbYsVbQro4tnV2dgZLx6effjpmWMs7tvXn448/FpIkiQcffFC0t7drBdedrqkzHwHGjx+P\nqqpUV1czc+bMRKKIih5vhkeAFaqq/ns/9WtPHOpXxES6urqCUl9raytDhgzRlWedaZrj+xVgyZIl\nuFwu9u/fr9ewuLDVL7DVr1jY6pfR2OpXf2z1qy//3OpXd3c3K1asQJIkw2b5J9pZNVz9Wrp0Kdu3\nbweI6KKRCJZRvwKGhRRaA8Z09au3t5fZs2cDvskTdXV1MdNOC/UrgNvtFg6HQ2RmZoqamhqt7k5c\nXR7THdsCcsOhQ4coKyszNHHTHdvq632rteqV8CyvfgW4fNlXVY4Y0beKvOOOO/p474ViefUrwJkz\nZwCYNWsW4CtcXnjhBc6fP691J62tfoUSeNeOHDnCxo0bAbQcbUpIB/UrdJpZ6DZz5syI4eNRv0xd\n3xJAksIfnuzsbC5evBhNejB28U6jfL8i0d3dTWdnJ3l5edx9991s3bqV4uLimHnWzLCflPp+RSIj\nI4OMjAx6e3sHGlUYpqpfycZWv8BWv2Jhq19GY6tf/bHVr778c6tfycD2/YqAoerX1atXKS4uJjs7\nm9ra2kSjCcPUaZ1er5eMjAwmTpxIfX09ra2tXLlyBZfLxejRo6Ola/1pnd3d3WLZsmXioYce6rOw\nWWdnZ6wFzUQ86SdbIAqoX2EaY2ZmJmPHjuWHH37oc3zv3r00Nzcbkrgp6ldnZydDhw4NLskToL29\nnffffz9mhJZXv65fv052djZut5uGhgZWrVqFJElMmDCBadOmRX3fIA0WNcvLy+PSpUsUFhYGj+3e\nvZtZs2bR2trK3r17teLVtahZso07TIQZig6Hg6NHj7Jr1y5uvfVW5s6dy9ixYwEYPnw4O3fuZMGC\nBbHiLUGH+pVU4wLrYAKl/c9NnTqVqVOnhl1z7dq1oCNpJPxVQTvwrFb6pqtf/fn0009pbGyMdeeM\n/bpLMn2/+nPp0iUjogEsoH5F4oEHHjAkHkuqXxoT4HWjaZyqql4g8DWSPwEH8alfSxRFqURnhRoP\nWVlZhsSju0Dxq18vAo8DDwJ/V1W1QVGUlcBtqqouiXG5KdKerX5hq1/Ww1a/ImCrX/EihGD9+vU0\nNTUZEZ111K/169cjSRKrV6825oNDkPBae1NlWf7Uvz9BluWjGtfExOv1Bh+7NWvWaAXXnc8BDeTL\nsnxMluWjsiwXxAi3KVZOt27dKhwOh1i7dq3o6enRMkzIsvylf5ueNON0/gM0fb/y8/MFEHVR6gjo\nTt90368rV65w4sSJ4IIvRmKq71dDQwMLFy6Mq4tjefUrwJYtW1i6dGnYXausrKS8vDziNZZXv8An\n7+3Zs4fKysrgsa6uLiZPnsypU7E+tgtYfUn/3t5e2tr+MXZy5MgRSktL9RgG6eD79eyzz4rS0lIh\ny3JYM6uoqCjiNWkz87GhoSFi+/HFF1+MNQNSd7qm+345HA5WrFjBunXrcDgcwaXpYqC/ztCyPpnf\nfBRCiD179giv1xsrSMJ3znT1q/80aiOxfb/A9v2Kha1+GY2tfvXHVr/6YqtfRmMZ9SsZWML3K1mY\nPvMxXtJi5qPT6Qxu8+bNE2632/CGc1K9GUKqjP/sf87l6lvFyrJMbm4ua9asCR575ZVXyMrK4osv\nvggNauzg4wDQnPnY09NDb28vM2bMoK6ujmXLljFu3Dg8Hk9wVmQo8ahfyTZOF5IkcfDgQS5cuEBu\nbi5Dhw6lo6OD3NzcsM6rqqqP+oeq1+JrxEePN3lZBmKoX5MmTQo7NnLkSIYOHcqCBQvIzc1l3rx5\nfVZ3C0HXzMdkFyiBAZMwfvrpJ7F8+fKIJUagoInwfRDhj7dCluV3tNJPujgUzwcthRBi27Ztwul0\nipycnIjn00b9CuX8+fMiJydHSJIktm/fHiuosVVBMtWvAGVlZRw4cAAhBC0tLeTk5EQLmj7qlxBC\nlJWVBd+zEydOaAXXfef0lJZ1wNP+fcPVr3379vHJJ58wZswYqqqqmDDBuG/0map+tbS0kJ+fjyRJ\ndHV16c6z3oCmql95eXn09PTEY1hcpEr9MoVUqV/WlPaw1S9b/bLVLyOx1a8IGK5+uVwu3nrrrYFE\nEYal1K+GhgbNpejiUb+SLRAV41tsVzMjLpcLIQRutztsSfF+JP0jsnpJ6IOWRmG6+hUvaeP7lQhp\ns+5XKEKIeJbqSZ91v8DnbCNJEps3b9YTvASrf9AyEh6PJ+b5eD5omXTFWVXVlcALBsYXc92sUNKu\nQIkHS0zrTMaaX2CRaZ0dHb65h4MGDTLUF8x0xzaAnJwcrVURE8J2bIP0dGzTO1YwDXgNn7QXUMA2\nAX8EsgChqqpxUrFBaN65EGlvRohhXwEFqqpOAT7G1xO3HHo+gPIcvsfubyGHW4ACoAnfOgkyMNFq\n6leiA4rvyrJcFvL7iCzLcqKjPHFi6CiPHmz1K9VYRv1KBpZSv/SQdr5fgU2SpOD+vffeO+ACxbR1\nv1pbWzl06FBw/XSAixcv8tprr7Fu3bo+U88SJsl3LlBl6GLNmjXC6XTGDCPLcq0sy7tkWc7XSt9S\nndVXX30VodGoSEv16+zZszgcDhwOBy+99BLl5eWMHDkybFU3P7rUL1PW/QLftM7Gxsag2vXRRx8F\nz23YsAGAXbt2RfvgXglWnvk4d+7cqKVlc3OzaG5ujvbOWd/364033hAejyf4e/LkyUKSJFFRURHR\nqBB0p2uacf0JGPftt98aZpwl1C+AEyd82q3G8FVcWEL9At8TNGjQoNQaR4oWNXM4HCxevJgxY8YY\nF6fQqDRDsdUvC/G7ntaZqPq1V1GUO/xBStDTWjCBRB3bqoCPFEVxo3OVUDNI1cqkpmCpLo/R2Mal\nK0kfEw8ZMBHAMlVVw+eNRb5uwO3ZpBrn9/26098u/QPwHjBFx3WGtGdT5vulquoZYLiiKMN0XGfI\nRI1U+34F3IVjjgYZtUhvqguUuJphA23PpnrdL90DJkZM1EiZ71c8AyZGtWdTsuq9f8CklxgDJv0w\npD1rty3TFdu4dMU2Ll2xjUtXftfG/T/Vcsa4u1nsxAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f01f3cf8b10>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load MNIST Data\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\n",
    "train_data = mnist.train.images # Returns np.array\n",
    "train_labels = np.asarray(mnist.train.labels, dtype=np.int32)\n",
    "eval_data = mnist.test.images # Returns np.array\n",
    "eval_labels = np.asarray(mnist.test.labels, dtype=np.int32)\n",
    "print(train_data.shape)\n",
    "print(train_labels.shape)\n",
    "print(eval_data.shape)\n",
    "print(eval_labels.shape)\n",
    "# Randomly choose 10 images from first 50 images of Train Data.\n",
    "for index,idx in enumerate(random.sample(range(50),10)): \n",
    "    plt.subplot(10,1,index+1)\n",
    "    plt.imshow(train_data[idx].reshape(28,28))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "W6I1p3uH5I18"
   },
   "source": [
    "Fill in the following snippet as per the instructions. \n",
    "* For initialising placeholders, use None to accommodate variable batch_size. \n",
    "* Do not change the seed; use it for comparing epoch-wise loss with your friends.\n",
    "* You can use the following <a href =\"https://www.tensorflow.org/versions/r1.1/get_started/mnist/beginners\">tutorial</a> for reference. Note that they use softmax in their example, while you are required to code Feedforward neural network. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "IqWoBVW9276e"
   },
   "outputs": [],
   "source": [
    "def initializer_1(shape):\n",
    "    # Do not change the seed.\n",
    "    np.random.seed(1)\n",
    "    return np.random.randn(*shape)\n",
    "\n",
    "def initializer_2(shape):\n",
    "    # Do not change the seed.\n",
    "    np.random.seed(1)\n",
    "    return 0.01 * np.random.randn(*shape)\n",
    "\n",
    "\n",
    "class MNIST_ANN:\n",
    "    def __init__(self, hidden_units, activations, initializer):\n",
    "        \"\"\"\n",
    "        Initialise the weights and build the compute graph. Use AdamOptimizer with default parameters.\n",
    "        :param hidden_units - list of number of hidden units.\n",
    "               Eg: [10,20] => Layer 1 has 10 hidden units and Layer 2 has 20.\n",
    "        :param activations - list of activations for each of the hidden layers.\n",
    "               Eg: [tf.nn.sigmoid, tf.nn.tanh]\n",
    "        :param intializer - the reference to the function used for intializing the weights\n",
    "        \"\"\"\n",
    "        # Define the placeholders\n",
    "        self.input =tf.placeholder(dtype=tf.float32,shape=[None,784])\n",
    "\n",
    "\n",
    "        self.expected_output = tf.placeholder(dtype=tf.float32,shape=[None,10])\n",
    "\n",
    "        # Initialise the weights and biases. Use zeros for the biases.\n",
    "        weights = [tf.Variable(dtype=tf.float32,initial_value=initializer([784,hidden_units[0]]))]\n",
    "        biases = [tf.Variable(dtype=tf.float32,initial_value=np.zeros(shape=[1,hidden_units[0]]))]\n",
    "\n",
    "        # Loop here.\n",
    "        for i in range(len(hidden_units)-1):\n",
    "            biases.append(tf.Variable(dtype=tf.float32,initial_value=np.zeros(shape=[1,hidden_units[i+1]])))\n",
    "            weights.append(tf.Variable(dtype=tf.float32,initial_value=initializer([hidden_units[i],hidden_units[i+1]])))\n",
    "\n",
    "        biases.append(tf.Variable(dtype=tf.float32, initial_value=np.zeros(shape=[1,10])))\n",
    "        weights.append(tf.Variable(dtype=tf.float32, initial_value=initializer([hidden_units[len(hidden_units)-1], 10])))\n",
    "\n",
    "\n",
    "\n",
    "        def graph_Builder(x):\n",
    "            for i in range(len(activations)):\n",
    "                x = activations[i](tf.matmul(x, weights[i]) + biases[i])\n",
    "            logit= tf.matmul(x, weights[len(activations)]) + biases[len(activations)]\n",
    "            pred=tf.nn.softmax(logit)\n",
    "            return logit,pred\n",
    "\n",
    "        # Build the graph for computing output.\n",
    "        self.output,self.pred=graph_Builder(self.input)\n",
    "\n",
    "        # # Define the loss and accuracy here. (Refer Tutorial)\n",
    "        self.cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=self.output,labels=self.expected_output))\n",
    "\n",
    "        self.accuracy = tf.reduce_mean(tf.cast(tf.equal(tf.argmax(self.pred, 1), tf.argmax(self.expected_output, 1)), tf.float32))\n",
    "        #\n",
    "        # # Instantiate the optimizer\n",
    "        optimizer=tf.train.AdamOptimizer()\n",
    "        #\n",
    "        self.train_op = optimizer.minimize(self.cost)\n",
    "        self.session = tf.Session()\n",
    "        #\n",
    "        # # Initialize all variables\n",
    "        self.init=tf.global_variables_initializer()\n",
    "\n",
    "    def train(self, train_data, train_labels, eval_data, eval_labels, batch_size, epochs=100):\n",
    "        \"\"\"\n",
    "        Training code.\n",
    "        \"\"\"\n",
    "        sess = self.session\n",
    "        sess.run(self.init)\n",
    "\n",
    "        # Slice the data and labels into batches depending on the batch_size.\n",
    "        batches = [[train_data[k:k+batch_size],train_labels[k:k+batch_size]] for k in range(0,len(train_data),batch_size)]\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            cost_epoch = 0\n",
    "            for batch in batches:\n",
    "                # Forward Propagate, compute cost and backpropagate.\n",
    "                cost, _ = sess.run([self.cost, self.train_op], feed_dict={self.input: batch[0],\n",
    "                                                                          self.expected_output: batch[1]})\n",
    "                cost_epoch += cost\n",
    "            if epoch % 10 == 0:\n",
    "                print(\"Train accuracy: {}\".format(self.compute_accuracy(train_data, train_labels)))\n",
    "                print(\"Test accuracy: {}\".format(self.compute_accuracy(eval_data, eval_labels)))\n",
    "            print(\"Epoch {}: {}\".format(epoch, cost_epoch))\n",
    "        print(\"Train accuracy: {}\".format(self.compute_accuracy(train_data, train_labels)))\n",
    "        print(\"Test accuracy: {}\".format(self.compute_accuracy(eval_data, eval_labels)))\n",
    "\n",
    "    def compute_accuracy(self, data, labels):\n",
    "        \"\"\"\n",
    "        Fill in code to compute accuracy\n",
    "        \"\"\"\n",
    "\n",
    "        _,acc= self.session.run([self.output,self.accuracy],feed_dict={self.input: data, self.expected_output: labels})\n",
    "\n",
    "        return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 10793,
     "status": "ok",
     "timestamp": 1526583313209,
     "user": {
      "displayName": "Nikhil Dhirmalani",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "117732879546167846741"
     },
     "user_tz": 180
    },
    "id": "_TTASFUA5I1_",
    "outputId": "5b0f39b9-76fd-4022-da2c-64f8e7c7643e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.780763626099\n",
      "Test accuracy: 0.791599988937\n",
      "Epoch 0: 6768.8649483\n",
      "Epoch 1: 3275.00305783\n",
      "Epoch 2: 2590.16955168\n",
      "Train accuracy: 0.873399972916\n",
      "Test accuracy: 0.876900017262\n"
     ]
    }
   ],
   "source": [
    "ann = MNIST_ANN([10],[tf.nn.sigmoid],initializer_1)\n",
    "ann.train(train_data,train_labels,eval_data,eval_labels,batch_size=10,epochs=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "maX6s20Q5I2B"
   },
   "source": [
    "The expected output for the above snippet is\n",
    "<pre>\n",
    "Train accuracy: 0.780763626099\n",
    "Test accuracy: 0.791599988937\n",
    "Epoch 0: 6768.86486949\n",
    "Epoch 1: 3275.00310887\n",
    "Epoch 2: 2590.16959983\n",
    "Train accuracy: 0.873399972916\n",
    "Test accuracy: 0.876900017262\n",
    "</pre>\n",
    "If you get any other output and you feel you are correct, you can proceed (However, I cannot think of any case where you can get a different output). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iJv-fmOh5I2B"
   },
   "source": [
    "### Answer the following questions by running code snippets. Unless asked explicitly (like in Q1 and Q4), you need to just show the system performance and need not comment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mmfIKKtm5I2D"
   },
   "source": [
    "**1. Use 1 hidden layer of 10 hidden units with sigmoid activation and batch_size=10 for this question. Observe the network performance for initializer_1 and initializer_2 and explain the behavior. Why does this happen? What is your guess for tanh and relu? Why?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "cellView": "code",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 833
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 56074,
     "status": "ok",
     "timestamp": 1526608035667,
     "user": {
      "displayName": "Nikhil Dhirmalani",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "117732879546167846741"
     },
     "user_tz": 180
    },
    "id": "RgmxIbr07Gxf",
    "outputId": "dabca683-975d-40d3-f9e6-cdef69153b3b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using initializer_2 for weights initialization\n",
      "Train accuracy: 0.888436377048\n",
      "Test accuracy: 0.889999985695\n",
      "Epoch 0: 4661.21876498\n",
      "Epoch 1: 2012.70547899\n",
      "Epoch 2: 1702.05737616\n",
      "Train accuracy: 0.916145443916\n",
      "Test accuracy: 0.911099970341\n",
      "\n",
      "\n",
      "using relu activation network performance with initialization_1\n",
      "Train accuracy: 0.329963624477\n",
      "Test accuracy: 0.326599985361\n",
      "Epoch 0: 13480.2653993\n",
      "Epoch 1: 7740.57294458\n",
      "Epoch 2: 5027.61890015\n",
      "Train accuracy: 0.773527264595\n",
      "Test accuracy: 0.771399974823\n",
      "\n",
      "\n",
      "using tanh activation network performance with initialization_1\n",
      "Train accuracy: 0.700636386871\n",
      "Test accuracy: 0.700600028038\n",
      "Epoch 0: 7810.33010177\n",
      "Epoch 1: 4358.57360845\n",
      "Epoch 2: 3468.85253896\n",
      "Train accuracy: 0.833999991417\n",
      "Test accuracy: 0.831900000572\n",
      "\n",
      "\n",
      "using relu activation network performance with initialization_2\n",
      "Train accuracy: 0.886363625526\n",
      "Test accuracy: 0.887300014496\n",
      "Epoch 0: 2797.41020327\n",
      "Epoch 1: 1812.86548536\n",
      "Epoch 2: 1694.94713\n",
      "Train accuracy: 0.901472747326\n",
      "Test accuracy: 0.898299992085\n",
      "\n",
      "\n",
      "using tanh activation network performance with initialization_1\n",
      "Train accuracy: 0.901745438576\n",
      "Test accuracy: 0.898599982262\n",
      "Epoch 0: 3125.41567938\n",
      "Epoch 1: 1666.60267279\n",
      "Epoch 2: 1505.20209847\n",
      "Train accuracy: 0.920145452023\n",
      "Test accuracy: 0.912699997425\n"
     ]
    }
   ],
   "source": [
    "#@title Default title text\n",
    "# Your code here.\n",
    "print (\"Using initializer_2 for weights initialization\")\n",
    "ann = MNIST_ANN([10],[tf.nn.sigmoid],initializer_2)\n",
    "ann.train(train_data,train_labels,eval_data,eval_labels,batch_size=10,epochs=3)\n",
    "print (\"\\n\\nusing relu activation network performance with initialization_1\")\n",
    "ann = MNIST_ANN([10],[tf.nn.relu],initializer_1)\n",
    "ann.train(train_data,train_labels,eval_data,eval_labels,batch_size=10,epochs=3)\n",
    "print (\"\\n\\nusing tanh activation network performance with initialization_1\")\n",
    "ann = MNIST_ANN([10],[tf.nn.tanh],initializer_1)\n",
    "ann.train(train_data,train_labels,eval_data,eval_labels,batch_size=10,epochs=3)\n",
    "\n",
    "print (\"\\n\\nusing relu activation network performance with initialization_2\")\n",
    "ann = MNIST_ANN([10],[tf.nn.relu],initializer_2)\n",
    "ann.train(train_data,train_labels,eval_data,eval_labels,batch_size=10,epochs=3)\n",
    "print (\"\\n\\nusing tanh activation network performance with initialization_1\")\n",
    "ann = MNIST_ANN([10],[tf.nn.tanh],initializer_2)\n",
    "ann.train(train_data,train_labels,eval_data,eval_labels,batch_size=10,epochs=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KUbB2OBFxsuA"
   },
   "source": [
    "**Observation**:- \n",
    "When we use initializer_1 to initialize weight matrix our cost does not reduces in comparision to initializing weights with initializer_2. Moreover the accuracy with initializer_2 is better in compare to initializer_1, when we use 10 hidden neurons with sigmoid activation in both cases. \n",
    "\n",
    "**Reason**:-\n",
    "For initializer_1 the weight matrix has weight initialized randomly in range between [0,1]. So if we do summation of weights with input we get very large value. This value is fed to sigmoid which has property of mapping significantly larger input mapped to 1, while significanly negative value gets mapped to zero. \n",
    "If the desired value of activation function is opposite side from where it satuarated. Now during training when SGD tries to update the weight it is not able make significant change in output of activation function. Thus networks ablity to learn is hindered and it becomes slow.\n",
    "\n",
    "In initializer_2 we have multiplied a scaling factor of 0.01 to make sure that values of weight are near zero. We canot make weights to zero as then it is unable to break the symmetry. So in this case out network learns faster, accuracy is better and chances of saturation is minimized.\n",
    "\n",
    "**Observation**:-\n",
    "For relu and tanh the accuracy is more and cost reduces significantly when weights are initialized with initialization_2. With initializer_2 relu and tanh has faster convergence than sigmoid.\n",
    "\n",
    "**Reason**:-\n",
    "The sigmoid function is prone to vanishing gradient issues which the ReLU does not suffer as much. Morover ReLU that do not have compact domains and tend not to have saturation problems to the same degree."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eysUpIUF5I2H"
   },
   "source": [
    "<b>2. Play around with different configurations of the system. Spend some time on <a href=\"https://playground.tensorflow.org/#activation=tanh&batchSize=10&dataset=circle&regDataset=reg-plane&learningRate=0.03&regularizationRate=0&noise=0&networkShape=4,2&seed=0.52239&showTestData=false&discretize=false&percTrainData=50&x=true&y=true&xTimesY=false&xSquared=false&ySquared=false&cosX=false&sinX=false&cosY=false&sinY=false&collectStats=false&problem=classification&initZero=false&hideText=false\"> Tensorflow Playground </a> to get a feel. Just demonstrate the performance of the system and make observations. No need to make any comments. </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 255
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 38624,
     "status": "ok",
     "timestamp": 1526608074318,
     "user": {
      "displayName": "Nikhil Dhirmalani",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "117732879546167846741"
     },
     "user_tz": 180
    },
    "id": "CYr-ppoI5I2H",
    "outputId": "f3b1d099-86f1-4eb1-9441-7f72a0210a1b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.793872714043\n",
      "Test accuracy: 0.794700026512\n",
      "Epoch 0: 4907.07815346\n",
      "Epoch 1: 3134.52599477\n",
      "Epoch 2: 2584.79183116\n",
      "Epoch 3: 2224.41481858\n",
      "Epoch 4: 1976.57729027\n",
      "Epoch 5: 1817.05124663\n",
      "Epoch 6: 1718.27467669\n",
      "Epoch 7: 1650.19419613\n",
      "Epoch 8: 1594.38904433\n",
      "Epoch 9: 1540.83657558\n",
      "Train accuracy: 0.909418165684\n",
      "Test accuracy: 0.901000022888\n"
     ]
    }
   ],
   "source": [
    "# Your code here.\n",
    "ann = MNIST_ANN([10,5],[tf.nn.relu,tf.nn.relu],initializer_2)\n",
    "ann.train(train_data,train_labels,eval_data,eval_labels,batch_size=10,epochs=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 255
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 39224,
     "status": "ok",
     "timestamp": 1526608113557,
     "user": {
      "displayName": "Nikhil Dhirmalani",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "117732879546167846741"
     },
     "user_tz": 180
    },
    "id": "UTAmxA6s7fzi",
    "outputId": "79fed14d-349d-4f12-8f2d-d02a34f44ea7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.816181838512\n",
      "Test accuracy: 0.810199975967\n",
      "Epoch 0: 4769.75287571\n",
      "Epoch 1: 2566.70410744\n",
      "Epoch 2: 2017.13873453\n",
      "Epoch 3: 1814.72325303\n",
      "Epoch 4: 1704.81400017\n",
      "Epoch 5: 1628.85116505\n",
      "Epoch 6: 1573.69350507\n",
      "Epoch 7: 1532.35536773\n",
      "Epoch 8: 1501.27642993\n",
      "Epoch 9: 1472.7861388\n",
      "Train accuracy: 0.917418181896\n",
      "Test accuracy: 0.90909999609\n"
     ]
    }
   ],
   "source": [
    "ann = MNIST_ANN([10,5],[tf.nn.tanh,tf.nn.relu],initializer_2)\n",
    "ann.train(train_data,train_labels,eval_data,eval_labels,batch_size=10,epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 255
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 38534,
     "status": "ok",
     "timestamp": 1526608152106,
     "user": {
      "displayName": "Nikhil Dhirmalani",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "117732879546167846741"
     },
     "user_tz": 180
    },
    "id": "ZPrrWJfa7irt",
    "outputId": "9cad583b-40fc-46bd-ee35-94f08cd0616b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.868090927601\n",
      "Test accuracy: 0.870599985123\n",
      "Epoch 0: 5236.57056016\n",
      "Epoch 1: 2135.36352523\n",
      "Epoch 2: 1678.34501727\n",
      "Epoch 3: 1499.62137046\n",
      "Epoch 4: 1389.3789269\n",
      "Epoch 5: 1309.38536741\n",
      "Epoch 6: 1247.67877976\n",
      "Epoch 7: 1199.48158493\n",
      "Epoch 8: 1160.71434403\n",
      "Epoch 9: 1127.96620816\n",
      "Train accuracy: 0.936309099197\n",
      "Test accuracy: 0.927100002766\n"
     ]
    }
   ],
   "source": [
    "ann = MNIST_ANN([10,10],[tf.nn.sigmoid,tf.nn.tanh],initializer_2)\n",
    "ann.train(train_data,train_labels,eval_data,eval_labels,batch_size=10,epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GE-NMOxC5I2J"
   },
   "source": [
    "<b>4. List the problems you faced while experimenting [Loss did not decrease, ran into NaNs, etc]. What conclusions did you make? </b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rSzqaar0bEka"
   },
   "source": [
    "I had to change the dimesions of matrices a lot in order to correctly perform matrix operations.\n",
    "While implementing multilayer perceptron, I had to check suitable loss function and read a lot about loss function and how to implement it in tensorflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "cAgyJK2Lbtd6"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "default_view": {},
   "name": "DeepLearningAssignment1.ipynb",
   "provenance": [
    {
     "file_id": "1hMHUUbBDjoXO70Lqv-GyDOc1NbSsb4cu",
     "timestamp": 1526355325040
    }
   ],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
